Name:                 nvidia-dcgm-exporter-n6jqs
Namespace:            nvidia-gpu-operator
Priority:             2000001000
Priority Class Name:  system-node-critical
Service Account:      nvidia-dcgm-exporter
Node:                 sno-arm/192.168.44.65
Start Time:           Fri, 21 Nov 2025 06:51:41 -0500
Labels:               app=nvidia-dcgm-exporter
                      controller-revision-hash=6bd699447c
                      pod-template-generation=1
Annotations:          k8s.ovn.org/pod-networks:
                        {"default":{"ip_addresses":["10.254.0.7/23"],"mac_address":"0a:58:0a:fe:00:07","gateway_ips":["10.254.0.1"],"routes":[{"dest":"10.254.0.0/...
                      k8s.v1.cni.cncf.io/network-status:
                        [{
                            "name": "ovn-kubernetes",
                            "interface": "eth0",
                            "ips": [
                                "10.254.0.7"
                            ],
                            "mac": "0a:58:0a:fe:00:07",
                            "default": true,
                            "dns": {}
                        }]
                      openshift.io/scc: lvms-vgmanager
Status:               Pending
IP:                   10.254.0.7
IPs:
  IP:           10.254.0.7
Controlled By:  DaemonSet/nvidia-dcgm-exporter
Init Containers:
  toolkit-validation:
    Container ID:  cri-o://fdefe3d8a0e7c5d47d8a39b395c196e35522d9d299e7b24e4b83487ebaca700a
    Image:         nvcr.io/nvidia/gpu-operator@sha256:d4841412c9b8d27c53b1588dcebffc5451e9ab0fd36b2c656c33a65356507cfd
    Image ID:      nvcr.io/nvidia/gpu-operator@sha256:04d31f9babb5567fe34d1b68124cf55fb5cddcf1e8c2d8a40fa5154d221a24ce
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
    Args:
      until [ -f /run/nvidia/validations/toolkit-ready ]; do echo waiting for nvidia container stack to be setup; sleep 5; done
    State:          Running
      Started:      Fri, 21 Nov 2025 06:51:42 -0500
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /run/nvidia from run-nvidia (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-qvrf4 (ro)
  init-pod-nvidia-node-status-exporter:
    Container ID:  
    Image:         nvcr.io/nvidia/cuda@sha256:d19fe621624c4eb6ac931b8558daa3ecc0c3f07f1e2a52e0267e083d22dceade
    Image ID:      
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/entrypoint.sh
    State:          Waiting
      Reason:       PodInitializing
    Ready:          False
    Restart Count:  0
    Environment:
      NVIDIA_DISABLE_REQUIRE:  true
    Mounts:
      /bin/entrypoint.sh from init-config (ro,path="entrypoint.sh")
      /var/lib/kubelet/pod-resources from pod-gpu-resources (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-qvrf4 (ro)
Containers:
  nvidia-dcgm-exporter:
    Container ID:   
    Image:          nvcr.io/nvidia/k8s/dcgm-exporter@sha256:ed2dfcb708949de649ab8e1b23521cfd1eba89774dbbe662b6835f1ffcaadb1a
    Image ID:       
    Port:           9400/TCP
    Host Port:      0/TCP
    State:          Waiting
      Reason:       PodInitializing
    Ready:          False
    Restart Count:  0
    Environment:
      DCGM_EXPORTER_LISTEN:         :9400
      DCGM_EXPORTER_KUBERNETES:     true
      DCGM_EXPORTER_COLLECTORS:     /etc/dcgm-exporter/dcp-metrics-included.csv
      NODE_NAME:                     (v1:spec.nodeName)
      DCGM_REMOTE_HOSTENGINE_INFO:  nvidia-dcgm:5555
    Mounts:
      /var/lib/kubelet/pod-resources from pod-gpu-resources (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-qvrf4 (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True 
  Initialized                 False 
  Ready                       False 
  ContainersReady             False 
  PodScheduled                True 
Volumes:
  pod-gpu-resources:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/kubelet/pod-resources
    HostPathType:  
  run-nvidia:
    Type:          HostPath (bare host directory volume)
    Path:          /run/nvidia
    HostPathType:  
  init-config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      nvidia-dcgm-exporter
    Optional:  false
  kube-api-access-qvrf4:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
    ConfigMapName:           openshift-service-ca.crt
    ConfigMapOptional:       <nil>
QoS Class:                   BestEffort
Node-Selectors:              nvidia.com/gpu.deploy.dcgm-exporter=true
Tolerations:                 node.kubernetes.io/disk-pressure:NoSchedule op=Exists
                             node.kubernetes.io/memory-pressure:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists
                             node.kubernetes.io/pid-pressure:NoSchedule op=Exists
                             node.kubernetes.io/unreachable:NoExecute op=Exists
                             node.kubernetes.io/unschedulable:NoSchedule op=Exists
                             nvidia.com/gpu:NoSchedule op=Exists
Events:                      <none>
